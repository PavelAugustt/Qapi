2025-11-08 18:59:20,244 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-11-08 18:59:20,245 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 18:59:20,250 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 18:59:21,481 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 18:59:21,485 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 18:59:28,428 ERROR app Thread-6 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\rules\message.py", line 36, in to_proto
    return self._descriptor(**value)
           ~~~~~~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\protobuf\internal\well_known_types.py", line 561, in _internal_assign
    self.update(dictionary)
    ~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\protobuf\internal\well_known_types.py", line 601, in update
    for key, value in dictionary.items():
                      ^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'items'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 108, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 166, in agent_execute
    response = chat.send_message(
        [{"function_response": {"name": function_name, "response": result}}]
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 564, in send_message
    content = content_types.to_content(content)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 296, in to_content
    return protos.Content(parts=[to_part(part) for part in content])
                                 ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 247, in to_part
    part = _convert_dict(part)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 171, in _convert_dict
    return protos.Part(part)
           ~~~~~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\message.py", line 728, in __init__
    pb_value = marshal.to_proto(pb_type, value)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\marshal.py", line 235, in to_proto
    pb_value = self.get_rule(proto_type=proto_type).to_proto(value)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\rules\message.py", line 46, in to_proto
    return self._wrapper(value)._pb
           ~~~~~~~~~~~~~^^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\message.py", line 728, in __init__
    pb_value = marshal.to_proto(pb_type, value)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\marshal.py", line 235, in to_proto
    pb_value = self.get_rule(proto_type=proto_type).to_proto(value)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\rules\struct.py", line 140, in to_proto
    k: self._marshal.to_proto(struct_pb2.Value, v) for k, v in value.items()
                                                               ^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'items'
2025-11-08 18:59:28,431 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 18:59:28] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:02:03,345 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:02:03,348 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:02:06,016 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:02:07,201 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:02:07,204 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:02:14,066 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-11-08 19:02:14,066 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:02:14,071 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:02:15,248 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:02:15,251 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:02:19,643 ERROR app Thread-6 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\rules\message.py", line 36, in to_proto
    return self._descriptor(**value)
           ~~~~~~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\protobuf\internal\well_known_types.py", line 561, in _internal_assign
    self.update(dictionary)
    ~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\protobuf\internal\well_known_types.py", line 601, in update
    for key, value in dictionary.items():
                      ^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'items'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 108, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 169, in agent_execute
    response = chat.send_message(
        [{"function_response": {"name": function_name, "response": result}}]
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 564, in send_message
    content = content_types.to_content(content)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 296, in to_content
    return protos.Content(parts=[to_part(part) for part in content])
                                 ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 247, in to_part
    part = _convert_dict(part)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 171, in _convert_dict
    return protos.Part(part)
           ~~~~~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\message.py", line 728, in __init__
    pb_value = marshal.to_proto(pb_type, value)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\marshal.py", line 235, in to_proto
    pb_value = self.get_rule(proto_type=proto_type).to_proto(value)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\rules\message.py", line 46, in to_proto
    return self._wrapper(value)._pb
           ~~~~~~~~~~~~~^^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\message.py", line 728, in __init__
    pb_value = marshal.to_proto(pb_type, value)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\marshal.py", line 235, in to_proto
    pb_value = self.get_rule(proto_type=proto_type).to_proto(value)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\proto\marshal\rules\struct.py", line 140, in to_proto
    k: self._marshal.to_proto(struct_pb2.Value, v) for k, v in value.items()
                                                               ^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'items'
2025-11-08 19:02:19,647 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:02:19] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:02:55,576 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:02:55,576 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:02:58,566 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:02:59,771 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:02:59,774 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:03:06,521 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-11-08 19:03:06,522 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:03:06,528 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:03:07,693 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:03:07,696 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:03:24,928 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:03:24] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:04:54,144 INFO werkzeug Thread-12 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:04:54] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:05:07,930 INFO werkzeug Thread-17 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:05:07] "POST /search HTTP/1.1" 200 -
2025-11-08 19:08:50,613 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\handlers.py', reloading
2025-11-08 19:08:50,614 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\handlers.py', reloading
2025-11-08 19:08:53,649 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:08:54,851 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:08:54,856 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:09:23,268 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:09:23,269 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:09:24,141 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:09:25,299 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:09:25,302 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:10:57,440 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-11-08 19:10:57,440 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:10:57,445 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:10:58,596 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:10:58,599 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:11:27,463 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:11:27] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:11:40,224 INFO werkzeug Thread-10 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:11:40] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:11:51,620 INFO werkzeug Thread-13 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:11:51] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:12:38,994 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:12:38,997 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:12:42,018 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:12:43,226 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:12:43,229 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:12:52,090 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-11-08 19:12:52,090 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:12:52,096 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:12:53,246 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:12:53,250 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:14:16,648 ERROR app Thread-6 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 136, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 181, in agent_execute
    response = chat.send_message(history_for_gemini)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 564, in send_message
    content = content_types.to_content(content)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 296, in to_content
    return protos.Content(parts=[to_part(part) for part in content])
                                 ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 264, in to_part
    return protos.Part(inline_data=to_blob(part))
                                   ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 210, in to_blob
    raise TypeError(
    ...<4 lines>...
    )
TypeError: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).
Got a: <class 'google.ai.generativelanguage_v1beta.types.content.Content'>
Value: parts {
  text: "\n    You are Qapi, a helpful AI assistant. Your goal is to help the user manage their tasks and goals.\n    You have access to a set of tools (functions) to interact with the user\'s data stores.\n    The available data stores and their schemas are documented in the ARCH_DESIGN.MD file.\n    When a user gives you an instruction, you should:\n    1.  Refer to the ARCH_DESIGN.MD file to understand the data structures.\n    2.  Decide which tools to use to fulfill the request.\n    3.  Call the tools with the correct parameters, ensuring the data you provide matches the schema.\n    4.  Use the tool outputs to formulate your final response.\n    5.  If you need to add a task with a reminder, add it to the \'timeheap\' data store.\n        A timeheap entry should be a JSON object with \'id\', \'description\', and \'due_date\' (in ISO format).\n    6.  When creating tasks, always include the consequences of not completing the task in the description.\n        This is very important. The consequences should be the worst-case scenario.\n    7.  When adding to a data store, you should first read the data store to see what is already there, and then append the new data.\n    8.  You can use \'delete_data_entry(store_name, entry_id)\' to remove an entry from a list-based data store.\n    9.  You can use \'load_memory(store_name, entry_id=None)\' to retrieve data from any store, either the entire store or a specific entry by ID.\n    \nUser instruction: What is the capital of France?"
}
role: "user"

2025-11-08 19:14:16,651 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:14:16] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:14:25,291 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-11-08 19:14:25,291 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:14:25,296 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:14:26,484 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:14:26,487 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:14:42,255 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:14:42,255 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:14:42,769 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:14:43,908 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:14:43,911 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:15:22,814 ERROR app Thread-6 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 136, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 182, in agent_execute
    response = chat.send_message(history_for_gemini)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 564, in send_message
    content = content_types.to_content(content)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 296, in to_content
    return protos.Content(parts=[to_part(part) for part in content])
                                 ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 264, in to_part
    return protos.Part(inline_data=to_blob(part))
                                   ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 210, in to_blob
    raise TypeError(
    ...<4 lines>...
    )
TypeError: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).
Got a: <class 'google.ai.generativelanguage_v1beta.types.content.Content'>
Value: parts {
  text: "\n    You are Qapi, a helpful AI assistant. Your goal is to help the user manage their tasks and goals.\n    You have access to a set of tools (functions) to interact with the user\'s data stores.\n    The available data stores and their schemas are documented in the ARCH_DESIGN.MD file.\n    When a user gives you an instruction, you should:\n    1.  Refer to the ARCH_DESIGN.MD file to understand the data structures.\n    2.  Decide which tools to use to fulfill the request.\n    3.  Call the tools with the correct parameters, ensuring the data you provide matches the schema.\n    4.  Use the tool outputs to formulate your final response.\n    5.  If you need to add a task with a reminder, add it to the \'timeheap\' data store.\n        A timeheap entry should be a JSON object with \'id\', \'description\', and \'due_date\' (in ISO format).\n    6.  When creating tasks, always include the consequences of not completing the task in the description.\n        This is very important. The consequences should be the worst-case scenario.\n    7.  When adding to a data store, you should first read the data store to see what is already there, and then append the new data.\n    8.  You can use \'delete_data_entry(store_name, entry_id)\' to remove an entry from a list-based data store.\n    9.  You can use \'load_memory(store_name, entry_id=None)\' to retrieve data from any store, either the entire store or a specific entry by ID.\n    "
}
role: "user"

2025-11-08 19:15:22,818 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:15:22] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:15:45,472 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:15:45,472 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:15:46,261 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:15:47,404 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:15:47,407 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:15:58,488 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-11-08 19:15:58,488 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:15:58,494 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:15:59,660 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:15:59,664 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:16:00,714 ERROR app Thread-6 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 136, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 178, in agent_execute
    response = chat.send_message(
        system_prompt + "\nUser instruction: " + user_prompt,
        history=history_for_gemini
    )
TypeError: ChatSession.send_message() got an unexpected keyword argument 'history'
2025-11-08 19:16:00,715 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:16:00] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:16:26,135 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:16:26,146 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:16:26,948 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:16:28,138 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:16:28,141 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:16:34,465 ERROR app Thread-6 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 136, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 182, in agent_execute
    response = chat.send_message(history_for_gemini)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 564, in send_message
    content = content_types.to_content(content)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 296, in to_content
    return protos.Content(parts=[to_part(part) for part in content])
                                 ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 264, in to_part
    return protos.Part(inline_data=to_blob(part))
                                   ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 210, in to_blob
    raise TypeError(
    ...<4 lines>...
    )
TypeError: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).
Got a: <class 'google.ai.generativelanguage_v1beta.types.content.Content'>
Value: parts {
  text: "\n    You are Qapi, a helpful AI assistant. Your goal is to help the user manage their tasks and goals.\n    You have access to a set of tools (functions) to interact with the user\'s data stores.\n    The available data stores and their schemas are documented in the ARCH_DESIGN.MD file.\n    When a user gives you an instruction, you should:\n    1.  Refer to the ARCH_DESIGN.MD file to understand the data structures.\n    2.  Decide which tools to use to fulfill the request.\n    3.  Call the tools with the correct parameters, ensuring the data you provide matches the schema.\n    4.  Use the tool outputs to formulate your final response.\n    5.  If you need to add a task with a reminder, add it to the \'timeheap\' data store.\n        A timeheap entry should be a JSON object with \'id\', \'description\', and \'due_date\' (in ISO format).\n    6.  When creating tasks, always include the consequences of not completing the task in the description.\n        This is very important. The consequences should be the worst-case scenario.\n    7.  When adding to a data store, you should first read the data store to see what is already there, and then append the new data.\n    8.  You can use \'delete_data_entry(store_name, entry_id)\' to remove an entry from a list-based data store.\n    9.  You can use \'load_memory(store_name, entry_id=None)\' to retrieve data from any store, either the entire store or a specific entry by ID.\n    "
}
role: "user"

2025-11-08 19:16:34,467 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:16:34] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:16:51,694 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-11-08 19:16:51,694 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:16:51,699 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:16:52,882 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:16:52,886 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:17:04,339 ERROR app Thread-6 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 136, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 182, in agent_execute
    response = chat.send_message(history_for_gemini)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 564, in send_message
    content = content_types.to_content(content)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 296, in to_content
    return protos.Content(parts=[to_part(part) for part in content])
                                 ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 264, in to_part
    return protos.Part(inline_data=to_blob(part))
                                   ~~~~~~~^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\types\content_types.py", line 210, in to_blob
    raise TypeError(
    ...<4 lines>...
    )
TypeError: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).
Got a: <class 'google.ai.generativelanguage_v1beta.types.content.Content'>
Value: parts {
  text: "\n    You are Qapi, a helpful AI assistant. Your goal is to help the user manage their tasks and goals.\n    You have access to a set of tools (functions) to interact with the user\'s data stores.\n    The available data stores and their schemas are documented in the ARCH_DESIGN.MD file.\n    When a user gives you an instruction, you should:\n    1.  Refer to the ARCH_DESIGN.MD file to understand the data structures.\n    2.  Decide which tools to use to fulfill the request.\n    3.  Call the tools with the correct parameters, ensuring the data you provide matches the schema.\n    4.  Use the tool outputs to formulate your final response.\n    5.  If you need to add a task with a reminder, add it to the \'timeheap\' data store.\n        A timeheap entry should be a JSON object with \'id\', \'description\', and \'due_date\' (in ISO format).\n    6.  When creating tasks, always include the consequences of not completing the task in the description.\n        This is very important. The consequences should be the worst-case scenario.\n    7.  When adding to a data store, you should first read the data store to see what is already there, and then append the new data.\n    8.  You can use \'delete_data_entry(store_name, entry_id)\' to remove an entry from a list-based data store.\n    9.  You can use \'load_memory(store_name, entry_id=None)\' to retrieve data from any store, either the entire store or a specific entry by ID.\n    "
}
role: "user"

2025-11-08 19:17:04,342 INFO werkzeug Thread-6 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:17:04] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:17:09,025 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:17:09,026 INFO werkzeug Thread-1 :  * Detected change in 'C:\\Users\\shrid\\Desktop\\Projects\\Qapi\\server\\app.py', reloading
2025-11-08 19:17:10,146 INFO werkzeug MainThread :  * Restarting with watchdog (windowsapi)
2025-11-08 19:17:11,316 WARNING werkzeug MainThread :  * Debugger is active!
2025-11-08 19:17:11,319 INFO werkzeug MainThread :  * Debugger PIN: 100-528-215
2025-11-08 19:17:26,024 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:17:26,025 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:17:32,193 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:17:32] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:17:45,469 ERROR app Thread-4 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 136, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 180, in agent_execute
    response = chat.send_message(
        system_prompt + "\nUser instruction: " + user_prompt
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 578, in send_message
    response = self.model.generate_content(
        contents=history,
    ...<5 lines>...
        request_options=request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 153, in retry_target
    _retry_error_helper(
    ~~~~~~~~~~~~~~~~~~~^
        exc,
        ^^^^
    ...<6 lines>...
        timeout,
        ^^^^^^^^
    )
    ^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 144, in retry_target
    result = target()
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 Please use a valid role: user, model.
2025-11-08 19:17:45,475 INFO werkzeug Thread-4 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:17:45] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:18:18,088 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:18:18,088 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:18:20,729 ERROR app Thread-1 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 136, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 180, in agent_execute
    response = chat.send_message(
        system_prompt + "\nUser instruction: " + user_prompt
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 578, in send_message
    response = self.model.generate_content(
        contents=history,
    ...<5 lines>...
        request_options=request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 153, in retry_target
    _retry_error_helper(
    ~~~~~~~~~~~~~~~~~~~^
        exc,
        ^^^^
    ...<6 lines>...
        timeout,
        ^^^^^^^^
    )
    ^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 144, in retry_target
    result = target()
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 Please use a valid role: user, model.
2025-11-08 19:18:20,733 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:18:20] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:22:56,833 ERROR app Thread-4 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 136, in instruct_llm
    system_instruction=system_prompt
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 180, in agent_execute
    
    
    # Append user's prompt to chatlog
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    append_data('chatlog', {"role": "user", "content": user_prompt, "timestamp": get_timestamp()})
    ^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 578, in send_message
    response = self.model.generate_content(
        contents=history,
    ...<5 lines>...
        request_options=request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 153, in retry_target
    _retry_error_helper(
    ~~~~~~~~~~~~~~~~~~~^
        exc,
        ^^^^
    ...<6 lines>...
        timeout,
        ^^^^^^^^
    )
    ^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 144, in retry_target
    result = target()
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 Please use a valid role: user, model.
2025-11-08 19:22:56,841 INFO werkzeug Thread-4 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:22:56] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:23:05,261 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:23:05,261 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:23:12,614 ERROR app Thread-1 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 155, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 179, in agent_execute
    response = chat.send_message(user_prompt)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 578, in send_message
    response = self.model.generate_content(
        contents=history,
    ...<5 lines>...
        request_options=request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 153, in retry_target
    _retry_error_helper(
    ~~~~~~~~~~~~~~~~~~~^
        exc,
        ^^^^
    ...<6 lines>...
        timeout,
        ^^^^^^^^
    )
    ^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 144, in retry_target
    result = target()
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 Please use a valid role: user, model.
2025-11-08 19:23:12,618 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:23:12] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:25:54,988 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:25:54,988 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:25:58,585 ERROR app Thread-1 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 154, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 200, in agent_execute
    response = chat.send_message(user_prompt)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 578, in send_message
    response = self.model.generate_content(
        contents=history,
    ...<5 lines>...
        request_options=request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 153, in retry_target
    _retry_error_helper(
    ~~~~~~~~~~~~~~~~~~~^
        exc,
        ^^^^
    ...<6 lines>...
        timeout,
        ^^^^^^^^
    )
    ^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 144, in retry_target
    result = target()
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 Please use a valid role: user, model.
2025-11-08 19:25:58,589 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:25:58] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:28:51,592 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:28:51,592 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:28:53,933 ERROR app Thread-1 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 154, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 166, in agent_execute
    client = genai.Client()
             ^^^^^^^^^^^^
AttributeError: module 'google.generativeai' has no attribute 'Client'
2025-11-08 19:28:53,935 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:28:53] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:29:29,680 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:29:29,681 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:29:32,338 ERROR app Thread-1 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 155, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 179, in agent_execute
    response = chat.send_message(user_prompt)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 578, in send_message
    response = self.model.generate_content(
        contents=history,
    ...<5 lines>...
        request_options=request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 153, in retry_target
    _retry_error_helper(
    ~~~~~~~~~~~~~~~~~~~^
        exc,
        ^^^^
    ...<6 lines>...
        timeout,
        ^^^^^^^^
    )
    ^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 144, in retry_target
    result = target()
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 Please use a valid role: user, model.
2025-11-08 19:29:32,361 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:29:32] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:29:36,582 ERROR app Thread-4 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 155, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 179, in agent_execute
    response = chat.send_message(user_prompt)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 578, in send_message
    response = self.model.generate_content(
        contents=history,
    ...<5 lines>...
        request_options=request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 153, in retry_target
    _retry_error_helper(
    ~~~~~~~~~~~~~~~~~~~^
        exc,
        ^^^^
    ...<6 lines>...
        timeout,
        ^^^^^^^^
    )
    ^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\retry\retry_unary.py", line 144, in retry_target
    result = target()
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 Please use a valid role: user, model.
2025-11-08 19:29:36,584 INFO werkzeug Thread-4 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:29:36] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:35:58,668 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:35:58,668 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:36:05,992 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:36:05] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:36:22,343 ERROR app Thread-4 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 155, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 207, in agent_execute
    glm.Content(role="tool", parts=[glm.Part(function_response=glm.FunctionResponse(name=function_name, response={"result": result}))])
    ^^^
NameError: name 'glm' is not defined
2025-11-08 19:36:22,345 INFO werkzeug Thread-4 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:36:22] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:36:52,880 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:36:52,880 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:36:57,086 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:36:57] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:37:07,057 ERROR app Thread-4 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 156, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 208, in agent_execute
    glm.Content(role="tool", parts=[glm.Part(function_response=glm.FunctionResponse(name=function_name, response={"result": result}))])
    ^^^^^^^^^^^
AttributeError: module 'google.generativeai.types' has no attribute 'Content'
2025-11-08 19:37:07,058 INFO werkzeug Thread-4 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:37:07] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 19:39:55,248 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 19:39:55,248 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 19:39:58,943 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:39:58] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:40:08,052 INFO werkzeug Thread-4 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:40:08] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:40:23,508 INFO werkzeug Thread-7 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:40:23] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:40:32,923 INFO werkzeug Thread-12 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:40:32] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:44:58,207 INFO werkzeug Thread-15 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:44:58] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:45:19,340 INFO werkzeug Thread-21 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:45:19] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:45:30,664 INFO werkzeug Thread-26 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:45:30] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:52:48,499 INFO werkzeug Thread-30 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:52:48] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:53:43,982 INFO werkzeug Thread-36 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:53:43] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:55:09,257 INFO werkzeug Thread-42 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:55:09] "GET /timeheap HTTP/1.1" 200 -
2025-11-08 19:55:43,559 INFO werkzeug Thread-43 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:55:43] "POST /instruct HTTP/1.1" 200 -
2025-11-08 19:55:49,686 INFO werkzeug Thread-49 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:55:49] "GET /timeheap HTTP/1.1" 200 -
2025-11-08 19:57:00,206 INFO werkzeug Thread-50 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 19:57:00] "GET /timeheap HTTP/1.1" 200 -
2025-11-08 20:00:39,765 ERROR app Thread-51 (process_request_thread) : An error occurred during agent execution.
Traceback (most recent call last):
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 155, in instruct_llm
    response = agent_execute(user_prompt)
  File "C:\Users\shrid\Desktop\Projects\Qapi\server\app.py", line 206, in agent_execute
    response = chat.send_message(
        [{"function_response": {"name": function_name, "response": {"result": result}}}]
    )
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 588, in send_message
    self._check_response(response=response, stream=stream)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\shrid\AppData\Local\Programs\Python\Python313\Lib\site-packages\google\generativeai\generative_models.py", line 616, in _check_response
    raise generation_types.StopCandidateException(response.candidates[0])
google.generativeai.types.generation_types.StopCandidateException: finish_reason: MALFORMED_FUNCTION_CALL
index: 0

2025-11-08 20:00:39,775 INFO werkzeug Thread-51 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:00:39] "[35m[1mPOST /instruct HTTP/1.1[0m" 500 -
2025-11-08 20:00:58,761 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 20:00:58,762 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 20:01:11,869 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:01:11] "POST /instruct HTTP/1.1" 200 -
2025-11-08 20:01:18,859 INFO werkzeug Thread-8 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:01:18] "GET /timeheap HTTP/1.1" 200 -
2025-11-08 20:07:18,400 INFO werkzeug Thread-9 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:07:18] "POST /instruct HTTP/1.1" 200 -
2025-11-08 20:07:27,640 INFO werkzeug Thread-15 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:07:27] "GET /timeheap HTTP/1.1" 200 -
2025-11-08 20:08:26,172 INFO werkzeug MainThread : [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.0.0.14:5000
2025-11-08 20:08:26,172 INFO werkzeug MainThread : [33mPress CTRL+C to quit[0m
2025-11-08 20:08:59,892 INFO werkzeug Thread-1 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:08:59] "POST /instruct HTTP/1.1" 200 -
2025-11-08 20:09:04,526 INFO werkzeug Thread-8 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:09:04] "GET /timeheap HTTP/1.1" 200 -
2025-11-08 20:10:07,442 INFO werkzeug Thread-9 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:10:07] "POST /instruct HTTP/1.1" 200 -
2025-11-08 20:10:13,915 INFO werkzeug Thread-14 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:10:13] "GET /timeheap HTTP/1.1" 200 -
2025-11-08 20:12:13,004 INFO werkzeug Thread-15 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:12:13] "POST /instruct HTTP/1.1" 200 -
2025-11-08 20:12:17,668 INFO werkzeug Thread-21 (process_request_thread) : 127.0.0.1 - - [08/Nov/2025 20:12:17] "GET /timeheap HTTP/1.1" 200 -
